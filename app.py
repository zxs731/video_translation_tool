
import gradio as gr
import time
from pathlib import Path 
import requests  
import json
import os
from dotenv import load_dotenv  
import io 
import base64  
import time  
import asyncio 
# åŠ è½½.envæ–‡ä»¶  
load_dotenv("en1.env")  

os.environ["OPENAI_API_TYPE"] = os.environ["Azure_OPENAI_API_TYPE1"]
os.environ["OPENAI_API_BASE"] = os.environ["Azure_OPENAI_API_BASE1"]
os.environ["OPENAI_API_KEY"] = os.environ["Azure_OPENAI_API_KEY1"]
os.environ["OPENAI_API_VERSION"] = os.environ["Azure_OPENAI_API_VERSION1"]
BASE_URL=os.environ["OPENAI_API_BASE"]
API_KEY=os.environ["OPENAI_API_KEY"]
Chat_Deployment=os.environ["Azure_OPENAI_Chat_API_Deployment"]
Whisper_key=os.environ["Azure_Whisper_API_KEY"]
Whisper_endpoint = os.environ["Azure_Whisper_API_Url"]
Azure_speech_key= os.environ["Azure_speech_key"]
Azure_speech_region= os.environ["Azure_speech_region"]
Azure_speech_speaker= os.environ["Azure_speech_speaker"]
os.environ["AZURE_API_KEY"] =API_KEY
os.environ["AZURE_API_BASE"] =BASE_URL
os.environ["AZURE_API_VERSION"] =os.environ["Azure_OPENAI_API_VERSION1"]
import os  
import subprocess  
  
  
def extract_audio(input_file, output_file):  
    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™åˆ é™¤  
    if os.path.exists(output_file):  
        os.remove(output_file)  
        
    command = [  
        'ffmpeg',  
        '-i', input_file,  
        '-q:a', '0',  
        '-map', 'a',  
        output_file  
    ]  
      
    try:  
        subprocess.run(command, check=True)  
        print(f"éŸ³é¢‘æˆåŠŸæå–å¹¶ä¿å­˜ä¸º {output_file}")  
    except subprocess.CalledProcessError as e:  
        print(f"é”™è¯¯ï¼š{e}")  

messages = []

prompt_input = ''

messages_text =[{"role":"system","content":"ä½ æ˜¯è§£ç­”é—®é¢˜çš„åŠ©æ‰‹ï¼Œæ€»æ˜¯èƒ½æ·±å…¥çš„å‰–æé—®é¢˜çš„æ ¹æœ¬ï¼Œå¹¶ç»™å‡ºè§£å†³é—®é¢˜çš„æ–¹æ³•ã€‚å³ä½¿ä¸èƒ½è§£å†³ä¹Ÿèƒ½æä¾›æ€è·¯ï¼Œå¼•å¯¼ç”¨æˆ·æŒ–æ˜æ›´å¤šä¿¡æ¯ã€‚"}]
import requests  
import json  
  
def update_video_translation(resource_key, operation_id, display_name, description,   
                             video_source_locale, translation_target_locale,   
                             voice_kind, speaker_count,   
                             subtitle_max_char_count_per_segment,   
                             export_subtitle_in_video,   
                             video_file_url, speech_region, translation_id):  
      
    url = f"https://{speech_region}.api.cognitive.microsoft.com/videotranslation/translations/{translation_id}?api-version=2024-05-20-preview"  
      
    headers = {  
        "Ocp-Apim-Subscription-Key": resource_key,  
        "Operation-Id": operation_id,  
        "Content-Type": "application/json"  
    }  
      
    data = {  
        "displayName": display_name,  
        "description": description,  
        "input": {  
            "sourceLocale": video_source_locale,  
            "targetLocale": translation_target_locale,  
            "voiceKind": voice_kind,  
            "speakerCount": speaker_count,  
            "subtitleMaxCharCountPerSegment": subtitle_max_char_count_per_segment,  
            "exportSubtitleInVideo": export_subtitle_in_video,  
            "videoFileUrl": video_file_url  
        }  
    }  
      
    response = requests.put(url, headers=headers, data=json.dumps(data),verify=False)  
      
    if response.status_code == 201 or response.status_code == 200:  
        print("Translation updated successfully.")  
        return response.json()  
    else:  
        print(f"Failed to update translation. Status code: {response.status_code}")  
        print(f"Response: {response.text}")  
        return None  
  
def update_translation_iteration(resource_key, operation_id, speaker_count,   
                                 subtitle_max_char_count_per_segment,   
                                 export_subtitle_in_video, webvtt_kind,   
                                 webvtt_url, speech_region, translation_id,   
                                 iteration_id):  
      
    url = f"https://{speech_region}.api.cognitive.microsoft.com/videotranslation/translations/{translation_id}/iterations/{iteration_id}?api-version=2024-05-20-preview"  
      
    headers = {  
        "Ocp-Apim-Subscription-Key": resource_key,  
        "Operation-Id": operation_id,  
        "Content-Type": "application/json"  
    }  
      
    data = {  
        "input": {  
            "speakerCount": speaker_count,  
            "subtitleMaxCharCountPerSegment": subtitle_max_char_count_per_segment,  
            "exportSubtitleInVideo": export_subtitle_in_video
            
        }  
    }  
    ''',  
            "webvttFile": {  
                "Kind": webvtt_kind,  
                "url": webvtt_url  
            }  
            '''  
    response = requests.put(url, headers=headers, data=json.dumps(data), verify=False)  
      
    if response.status_code == 201 or response.status_code == 200:  
        print("Translation iteration updated successfully.")  
        return response.json()  
    else:  
        print(f"Failed to update translation iteration. Status code: {response.status_code}")  
        print(f"Response: {response.text}")  
        return None  
        
def get_video_translation_operation(resource_key, operation_id, speech_region):  
    url = f"https://{speech_region}.api.cognitive.microsoft.com/videotranslation/operations/{operation_id}?api-version=2024-05-20-preview"  
      
    headers = {  
        "Ocp-Apim-Subscription-Key": resource_key  
    }  
      
    response = requests.get(url, headers=headers,verify=False)  
      
    if response.status_code == 200:  
        print("Operation details retrieved successfully.")  
        return response.json()  
    else:  
        print(f"Failed to retrieve operation details. Status code: {response.status_code}")  
        print(f"Response: {response.text}")  
        return None 

def get_video_translation_iteration(resource_key, translation_id, iteration_id, speech_region):  
    url = f"https://{speech_region}.api.cognitive.microsoft.com/videotranslation/translations/{translation_id}/iterations/{iteration_id}?api-version=2024-05-20-preview"  
      
    headers = {  
        "Ocp-Apim-Subscription-Key": resource_key  
    }  
      
    response = requests.get(url, headers=headers,verify=False)  
      
    if response.status_code == 200:  
        print("Iteration details retrieved successfully.")  
        return response.json()  
    else:  
        print(f"Failed to retrieve iteration details. Status code: {response.status_code}")  
        print(f"Response: {response.text}")  
        return None  

import random  
  
def generate_random_number():  
    # ç”Ÿæˆä¸€ä¸ª 6 ä½çš„éšæœºæ•°  
    random_number = random.randint(100000, 999999)  
    return random_number  
    
# å¯é€‰çš„è¯­è¨€åˆ—è¡¨  
language_options = {  
    "English": "en-US",  
    "Chinese": "zh-CN",
    "Japanese":"ja-JP",
    "French": "fr-FR",  
    "Spanish": "es-ES",  
    "German": "de-DE"  
}  

myfile=''
def handle_video(audio, source_language, target_language):
    global messages_text,myfile
    print(source_language)
    cont=None
    sourceLc = language_options[source_language]
    targetLc = language_options[target_language]
    if audio is None:
        error_html = """  
    <div style="position: relative; width: 600px;">  
        <div style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); color: white; font-size: 24px; background: rgba(0, 0, 0, 0.5); padding: 10px; border-radius: 5px;">  
            Please choose video first!
        </div>  
    </div>  
    """  
        yield error_html
        return error_html
        
    # è¿”å›â€œæ­£åœ¨åŠ è½½...â€çš„HTML  
    loading_html = """  
    <div style="position: relative; width: 600px;">  
        <div style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); color: white; font-size: 24px; background: rgba(0, 0, 0, 0.5); padding: 10px; border-radius: 5px;">  
            Processing...  
        </div>  
    </div>  
    """  
    yield loading_html
    if audio is not None:
        myfile=Path(audio)
        blob_name = os.path.basename(myfile)  
        video_url=uploadVideo()
        

  
        # ç¤ºä¾‹è°ƒç”¨  
        random_number = generate_random_number()  
        operation_id=f"{blob_name}_opr_{random_number}"
        translation_id=f"{blob_name}_tran_{random_number}"
        iteration_id=f"{blob_name}_iter_{random_number}"
        resource_key=os.environ["Azure_translate_key"]
        video_source_locale=sourceLc
        translation_target_locale=targetLc
        speech_region=os.environ["Azure_translate_region"]
        video_file_url=video_url
            
        # ç”¨å®é™…å‚æ•°è°ƒç”¨  
        result = update_video_translation(  
            resource_key=resource_key,  
            operation_id=operation_id,  
            display_name="videotrans001",  
            description="videotrans001des",  
            video_source_locale=video_source_locale,  
            translation_target_locale=translation_target_locale,  
            voice_kind="PlatformVoice",  
            speaker_count=1,  
            subtitle_max_char_count_per_segment=30,  
            export_subtitle_in_video=True,  
            video_file_url=video_file_url,  
            speech_region=speech_region,  
            translation_id=translation_id 
        )    
        
        result = get_video_translation_operation(  
            resource_key=resource_key,  
            operation_id=operation_id,  
            speech_region=speech_region
        )  
        while result["status"]!='Succeeded':
            # æš‚åœ 1 ç§’é’Ÿ  
            time.sleep(1) 
            result = get_video_translation_operation(  
                resource_key=resource_key,  
                operation_id=operation_id,  
                speech_region=speech_region
            )
            yield loading_html
            
        result = update_translation_iteration(  
            resource_key=resource_key,  
            operation_id=operation_id+"01",  
            speaker_count=1,  
            subtitle_max_char_count_per_segment=30,  
            export_subtitle_in_video=True,  # æ³¨æ„è¿™é‡Œä½¿ç”¨ True è€Œé true  
            webvtt_kind="en-US",  # æ ¹æ®æ‚¨çš„éœ€æ±‚è°ƒæ•´  
            webvtt_url=f"{os.environ['Azure_storage_endpoint']}/video/azure_ai_001.mp4?{os.environ['Azure_storage_sgs']}",  
            speech_region=speech_region,  
            translation_id=translation_id,  
            iteration_id=iteration_id
        )     
        result = get_video_translation_iteration(  
            resource_key=resource_key,  
            translation_id=translation_id,  
            iteration_id=iteration_id,  
            speech_region=speech_region
        )  
        while result["status"]!='Succeeded':
            print(result)
            # æš‚åœ 1 ç§’é’Ÿ  
            time.sleep(1) 
            
            result = get_video_translation_iteration(  
                    resource_key=resource_key,  
                    translation_id=translation_id,  
                    iteration_id=iteration_id,  
                    speech_region=speech_region
                )  
            yield loading_html
            
        print(result["result"]["translatedVideoFileUrl"])   
        result = get_video_translation_iteration(  
                resource_key=resource_key,  
                translation_id=translation_id,  
                iteration_id=iteration_id,  
                speech_region=speech_region
            )  
        
        video_url=result["result"]["translatedVideoFileUrl"]
        print(video_url)
        # ä½¿ç”¨ HTML çš„ <video> æ ‡ç­¾æ¥åµŒå…¥è§†é¢‘  
    video_html = f"""  
    <video width="600" controls>  
        <source src="{video_url}" type="video/mp4">  
        Your browser does not support the video tag.  
    </video>  
    """  
    yield video_html
    return video_html  
    #return v

def handle_gpt(input):
    if input is None:
        return ""
    completion=chatgpt(messages_text[-20:])
    cont=completion["choices"][0]["message"]["content"]

    #if cont is not None:
    #    speak(cont)
    return cont
    
def handle_conv(cont):
    if cont:
        assistant_msg={"role": "assistant", "content":cont}
        messages_text.append(assistant_msg)
    print(assistant_msg)    
    dialogue_string = ""  
    for message in messages_text: 
        role = message["role"]  
        if role=="system":
            continue
        content = message["content"]
        avatar="ğŸ¤–"
        if role=="user":
            avatar="ğŸ‘¨"
        dialogue_string += f"{avatar} {role}: {content}\n"
    return dialogue_string
    
def whisper(myfile):
    url = Whisper_endpoint
    headers = {'api-key': Whisper_key}  
    files = {  
        "file": open(myfile, "rb")  
    }  

    response = requests.post(url, headers=headers, files=files,verify=False)
    return response


    
def Reset():
    global messages_text
    messages_text =[{"role":"system","content":"ä½ æ˜¯è§£ç­”é—®é¢˜çš„åŠ©æ‰‹ã€‚"}]
    return ""
    
def CreateIndex(text):
    global myfile
    video_url = uploadVideo()
    print('create index...')
    blob_name = blob_name = os.path.basename(myfile)   
    b64FileName = convert_to_base64(blob_name)

    return "index done sucessfully!"
    
def uploadVideo():
    global myfile
    print('upload video...')
    from azure.storage.blob import BlobServiceClient  
    import os  
    # Azure Storage Account ä¿¡æ¯  
    connection_string = os.environ['Azure_storage_connectionstring']  # æ›¿æ¢ä¸ºæ‚¨çš„è¿æ¥å­—ç¬¦ä¸²  
    container_name = "video"          # æ›¿æ¢ä¸ºæ‚¨çš„å®¹å™¨åç§°  
    file_path =myfile             # æ›¿æ¢ä¸ºæ‚¨çš„æœ¬åœ°æ–‡ä»¶è·¯å¾„  
    blob_name = os.path.basename(file_path)          # ä½¿ç”¨æ–‡ä»¶åä½œä¸º Blob åç§°  
      
    # åˆ›å»º BlobServiceClient å®ä¾‹  
    blob_service_client = BlobServiceClient.from_connection_string(connection_string)  
      
    # è·å–å®¹å™¨å®¢æˆ·ç«¯  
    container_client = blob_service_client.get_container_client(container_name)  
      
    # ä¸Šä¼ æ–‡ä»¶  
    with open(file_path, "rb") as data:  
        container_client.upload_blob(name=blob_name, data=data, overwrite=True)  
      
    print(f"æ–‡ä»¶ {file_path} å·²æˆåŠŸä¸Šä¼ åˆ° Azure Blob å­˜å‚¨ä¸­çš„ {blob_name}")  
    vedio_url = f"{os.environ['Azure_storage_endpoint']}/video/{blob_name}?{os.environ['Azure_storage_sgs']}"
    print(vedio_url)
    return vedio_url

def convert_to_base64(original_string):  
    # å°†å­—ç¬¦ä¸²ç¼–ç ä¸ºå­—èŠ‚  
    string_bytes = original_string.encode('utf-8')  
      
    # è½¬æ¢ä¸ºBase64  
    base64_bytes = base64.b64encode(string_bytes)  
      
    # å°†Base64å­—èŠ‚è½¬æ¢ä¸ºå­—ç¬¦ä¸²  
    base64_string = base64_bytes.decode('utf-8')  
      
    return base64_string  
    
import requests  
  



out_speak=gr.Video(label="âš¡ Translated âš¡:",visible=True)

# åˆ›å»º Gradio æ¥å£  
with gr.Interface(  
    title="ğŸ’Translate VideoğŸ’",  
    description="This is demo by ğŸš©Azure speechğŸ¤Azure Video Translateâš¡Azure AIğŸš€",  
    fn=handle_video,  
    outputs=gr.HTML(),  
    inputs=[gr.Video(sources=["upload"], label="Video Input ğŸ¥"),gr.Dropdown(label="Source", choices=list(language_options.keys())),  gr.Dropdown(label="Target", choices=list(language_options.keys()))  ],  
    live=True,
    allow_flagging="never",
) as demo:  
    btn = gr.Button("ğŸ•— Create Index",visible=False)


if __name__ == "__main__":
    demo.launch(share=True)


